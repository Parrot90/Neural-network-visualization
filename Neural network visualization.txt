The interface should replicate the structure and behavior shown in the reference screenshot, with three main sections: an inference canvas, a prediction chart, and a model playground. The inference section should feature a pixelated 28x28 canvas where users can draw digits, along with a "Clear" button to reset the input. This canvas input should be converted into a 784-dimensional vector for model inference. The prediction section must display a dynamic horizontal bar chart showing confidence scores for digits 0 through 9, with the highest-confidence digit clearly highlighted. The model playground should visually represent the neural network architecture, consisting of an input layer with 784 neurons, a hidden layer with 256 neurons using ReLU activation, a second hidden layer with 128 neurons also using ReLU, and an output layer with 10 neurons using softmax activation. Users should be able to configure training parameters such as number of epochs (default: 5), batch size (default: 16), and training size (default: 3000 samples), and initiate training via a "Train Model" button. The system should train on the MNIST dataset, normalize input pixel values to [0, 1], and split the data into training and validation sets. During training, a line chart should display both training loss and validation loss over epochs, and the final accuracy should be shown prominently. The UI should be clean and responsive, built with HTML/CSS or TailwindCSS, and use Chart.js or D3.js for visualizations. Bonus features should include saving the trained model in browser storage (IndexedDB), allowing users to test with preloaded MNIST samples, exporting the model architecture as JSON, toggling between CPU and WebGL backends for performance, and optionally animating neuron activations during inference for visual flair. The entire system should run client-side and be optimized for interactivity, clarity, and educational value.
